# 🕷️ 網頁爬蟲任務

## 🎯 任務目標

學習如何用自然語言讓 AI 幫你從網頁自動抓取資料。

---

## ⚠️ 重要提醒

爬蟲前請注意：
1. **遵守網站的 robots.txt 規則**
2. **不要過度頻繁請求**（建議加上延遲）
3. **僅用於學習和個人用途**
4. **尊重網站的使用條款**

---

## 📂 測試資料說明

資料夾中提供了：

| 檔案 | 說明 |
|------|------|
| `sample_urls.txt` | 測試用網址清單 |
| `results/` | 爬蟲結果儲存資料夾 |

---

## 💬 範例對話

### 情境 1：抓取網頁文字內容

**你可以這樣說：**

```
我想抓取這個網頁的文章標題和內容
網址是：https://example.com/article
```

**進階要求（可選）：**

```
存成 TXT 檔，檔名用日期命名
```

```
只抓取 <div class="article"> 裡的內容
```

---

### 情境 2：批次抓取多個網頁

**你可以這樣說：**

```
我有一個 URLs 清單在 urls.txt 檔案裡，想批次抓取所有網頁的標題
```

**進階要求（可選）：**

```
每個請求間隔 2 秒（避免過度請求），儲存成 CSV
```

```
如果抓取失敗就跳過，繼續下一個
```

💡 **重點技巧**：
- 加上延遲避免被封鎖
- 設定錯誤處理機制
- 儲存成結構化格式（CSV、Excel）

---

### 情境 3：抓取表格資料

**你可以這樣說：**

```
我想抓取這個網頁上的表格：https://example.com/data-table
```

**進階要求（可選）：**

```
轉換成 Excel 檔案，保留原有格式
```

```
如果有多個表格，只抓取第一個
```

---

### 情境 4：監控網頁變化

**你可以這樣說：**

```
我想監控這個網頁的價格，如果價格有變動就通知我
網址是：https://example.com/product
每小時檢查一次
```

**進階要求（可選）：**

```
價格變動時發送 Email 通知
```

```
記錄歷史價格，可以畫趨勢圖
```

---

## 🎓 學到的技巧

1. **網頁結構分析**：了解如何定位要抓取的內容
2. **批次處理**：一次抓取多個網頁
3. **資料清洗**：去除不需要的標籤和格式
4. **錯誤處理**：網頁無法訪問時的應對
5. **禮貌爬蟲**：加入延遲，避免造成伺服器負擔

---

## 🚀 現在輪到你了！

開啟 Copilot Chat (`Ctrl+I` 或 `Cmd+I`)，試著對話：

### 練習 1：抓取單一網頁

```
幫我抓取 https://example.com 的所有文章標題，儲存成 TXT 檔案
```

### 練習 2：抓取表格資料

```
從 https://example.com/table 抓取表格，轉換成 Excel 檔案
```

### 練習 3：批次抓取

```
我有一個網址清單在 urls.txt，批次抓取所有網頁的標題和摘要，儲存成 CSV
```

### 練習 4：定時爬蟲

```
建立一個自動化腳本，每天早上 9 點抓取新聞標題，儲存到 news_archive 資料夾
```

---

## 💡 提示

### 如何描述要抓取的內容

✅ **好的描述**：
```
抓取 <div class="article"> 裡的所有文字
```

```
抓取網頁上所有的產品名稱和價格
```

❌ **不好的描述**：
```
抓取網頁內容（太籠統）
```

### 常見爬蟲場景

| 場景 | 抓取項目 |
|------|----------|
| 新聞資訊 | 標題、內容、發布時間 |
| 商品資訊 | 名稱、價格、規格、評價 |
| 表格資料 | 股價、匯率、統計數據 |
| 圖片下載 | 批次下載網頁上的圖片 |
| 監控變化 | 價格、庫存、內容更新 |

### 爬蟲的黃金法則

1. **先檢查 API**：有些網站提供官方 API，優先使用
2. **加上延遲**：每個請求間隔 1-2 秒
3. **設定 User-Agent**：模擬瀏覽器訪問
4. **錯誤重試**：網路不穩定時自動重試
5. **記錄日誌**：方便追蹤和除錯

---

## 🛠️ 常用爬蟲技術

| 技術類型 | 適用情境 | 工具 |
|----------|----------|------|
| 簡單網頁爬蟲 | 靜態 HTML 網頁 | requests + BeautifulSoup |
| 動態網頁爬蟲 | JavaScript 渲染的網頁 | Selenium + WebDriver |
| API 爬蟲 | 提供 API 的網站 | requests + JSON |

---

## 🎯 挑戰任務

### 🥇 初級挑戰
- [ ] 抓取一個新聞網站的最新 10 則標題
- [ ] 下載網頁上的所有圖片
- [ ] 抓取表格資料並轉存為 CSV

### 🥈 中級挑戰
- [ ] 批次抓取多個網站的內容
- [ ] 建立價格監控機器人
- [ ] 抓取並分析評論情感

### 🥉 高級挑戰
- [ ] 建立自動化新聞彙整系統
- [ ] 爬取電商網站的商品比價
- [ ] 建立每日定時爬蟲並發送通知

---

## 🌟 小技巧

### 如何處理爬蟲常見問題

**問題 1：網頁載入很慢**
```
網頁載入超過 30 秒，可以設定超時嗎？設定 timeout=10 秒，超時就跳過
```

**問題 2：被網站封鎖**
```
出現 403 錯誤，可能是因為：
1. 請求太頻繁 → 加大延遲時間
2. 沒有 User-Agent → 加上瀏覽器標頭
```

**問題 3：資料不完整**
```
抓到的內容不完整，可能原因：
1. 網頁是動態載入 → 改用 Selenium
2. 內容在 iframe 裡 → 需要特殊處理
```

---

## ⚖️ 法律與道德考量

使用爬蟲時請注意：

1. **個人資料保護**：不要抓取敏感個人資訊
2. **著作權**：尊重內容版權，僅供個人學習
3. **使用條款**：遵守網站的服務條款
4. **公平使用**：不要對伺服器造成過大負擔
5. **robots.txt**：遵守網站的爬蟲規則

---

記住：**做一個有禮貌的爬蟲工程師！** 🕷️
